{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62c2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sayan/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/sayan/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "model_resnet50 = models.resnet50(pretrained=True)\n",
    "model_resnet50 = torch.nn.Sequential(*(list(model_resnet50.children())[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5a02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcgrad import PCGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f95da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list(data_dir):\n",
    "\n",
    "    # list of image files and corresponding labels\n",
    "    files_list = []\n",
    "    x = os.walk(data_dir, topdown=False)\n",
    "    j=-1\n",
    "    for path,d,filelist in sorted(x):\n",
    "        if j !=-1:\n",
    "            kkk=path.split(os.sep)\n",
    "            label_name = kkk[-1]\n",
    "            \n",
    "            for filename in sorted(filelist):\n",
    "\n",
    "                file_glob = os.path.join(path, filename)\n",
    "                files_list.extend([(glob.glob(file_glob),j, label_name)])\n",
    "                          \n",
    "        j=j+1\n",
    "    print(j)\n",
    "\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "621f5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader_single(data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        \n",
    "        mean_pix = [0.485, 0.456, 0.406]\n",
    "        std_pix = [0.229, 0.224, 0.225]\n",
    "        normalize = transforms.Normalize(mean=mean_pix, std=std_pix)\n",
    "        \n",
    "        self.transformer_src = transforms.Compose([transforms.Resize(256),\n",
    "                                                transforms.RandomCrop(224),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                normalize])\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return_val = []\n",
    "               \n",
    "        source_img = Image.open(self.dataset[index][0][0]).convert('RGB')\n",
    "        source_label = torch.tensor(self.dataset[index][1], dtype=torch.long)\n",
    "        source_img = self.transformer_src(source_img)\n",
    "        image_label_name = self.dataset[index][2]\n",
    "        \n",
    "        return_val.append((source_img, source_label, image_label_name))\n",
    "        \n",
    "        return return_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482e1783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_loader(dataset1, \n",
    "                   batch_size=4, shuffle=True, \n",
    "                   drop_last=True):\n",
    "    \n",
    "    train_loader = data_loader_single(dataset1)\n",
    "    loader_train = torch.utils.data.DataLoader(train_loader,batch_size=batch_size, \n",
    "                                                      shuffle=shuffle, drop_last=drop_last)\n",
    "    \n",
    "    return loader_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd97c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe8c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            model_resnet50,\n",
    "            nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9607fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainClassifier(nn.Module): # source classifier\n",
    "    def __init__(self, input_dim):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.numclasses = numclasses\n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(input_dim, 100))\n",
    "        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n",
    "        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n",
    "\n",
    "    def forward(self, input_data, alpha=1):\n",
    "        \n",
    "        reverse_feature = ReverseLayerF.apply(input_data, alpha)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f62fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassClassifier(nn.Module): # source classifier\n",
    "    def __init__(self, input_dim, numclasses):\n",
    "        super(ClassClassifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.numclasses = numclasses\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(input_dim, 1024))\n",
    "        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(1024))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_drop1', nn.Dropout2d())\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(1024, 512))\n",
    "        self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(512))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(512, numclasses))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n",
    "        \n",
    "    def forward(self, input_features):\n",
    "        \n",
    "        classifier_output = self.class_classifier(input_features)\n",
    "\n",
    "        return classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30abf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a433548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(t_file_list, base_model, ClassClassifier):\n",
    "    \n",
    "    base_model.eval(), ClassClassifier.eval()\n",
    "    \n",
    "    test_dataLoader = dataset_loader(t_file_list, batch_size= 10, drop_last=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        acc = 0\n",
    "        \n",
    "        for i, batch in enumerate(test_dataLoader):\n",
    "            image = batch[0][0].to(device)\n",
    "            label = batch[0][1]\n",
    "            \n",
    "            prob = ClassClassifier(base_model(image))            \n",
    "            cl_pred=torch.argmax(prob.cpu(), dim = 1)\n",
    "            acc += torch.sum(cl_pred == label).item()\n",
    "            \n",
    "        acc/=len(t_file_list)\n",
    "            \n",
    "        return acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9830ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot(epochs, loss):\n",
    "    plt.plot(epochs, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc649926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(root, dataset, base_model, classifier, discriminator, criterion, optimizer,Source, \n",
    "             target, device, num_epoch, save_path, batch_size, shuffle1, drop_last):\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    base_model=base_model.to(device)\n",
    "    base_model=base_model.train()\n",
    "    \n",
    "    classifier=classifier.to(device)\n",
    "    classifier=classifier.train()\n",
    "    \n",
    "    discriminator=discriminator.to(device)\n",
    "    discriminator=discriminator.train()\n",
    "    \n",
    "    \n",
    "    criterion=criterion.to(device)\n",
    "    \n",
    "    loss_class = torch.nn.NLLLoss()\n",
    "    loss_class = loss_class.to(device)\n",
    "    \n",
    "    loss_domain = torch.nn.NLLLoss()\n",
    "    loss_domain = loss_domain.to(device)\n",
    "    \n",
    "    s1_path = os.path.join(root, dataset, Source)\n",
    "    s1_file_list = file_list(s1_path)\n",
    "    \n",
    "    t_path = os.path.join(root, dataset, target)\n",
    "    t_file_list = file_list(t_path)\n",
    "    \n",
    "    cl_loss_list = []\n",
    "    d_loss_list = []\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        base_model=base_model.train()\n",
    "        classifier=classifier.train()\n",
    "        discriminator=discriminator.train()\n",
    "        \n",
    "        print(\"epoch___________________\", epoch)\n",
    "        step=0\n",
    "        cl_loss_avg=0\n",
    "        d_loss_avg = 0\n",
    "        \n",
    "        S1_dataload = dataset_loader(s1_file_list, batch_size= batch_size)\n",
    "        \n",
    "        t1_dataload = dataset_loader(t_file_list, batch_size= batch_size)\n",
    "        \n",
    "        n_batch_S = len(S1_dataload)\n",
    "        #print(n_batch_S)\n",
    "        s1_iter = iter(S1_dataload)\n",
    "        #print(len(s1_iter))        \n",
    "        \n",
    "        n_batch_t = len(t1_dataload)\n",
    "        t_iter = iter(t1_dataload)\n",
    "        \n",
    "        iteration = np.max([n_batch_S, n_batch_t])\n",
    "        \n",
    "        \n",
    "        ### ________________________ iteration ___________________###\n",
    "        \n",
    "        for i in tqdm(range(iteration)):\n",
    "            \n",
    "            pp1 = float(i + epoch * iteration) / num_epoch / iteration\n",
    "            alpha = 2. / (1. + np.exp(-10 * pp1)) - 1\n",
    "            \n",
    "            if step%n_batch_S == 0:\n",
    "                s1_iter=iter(S1_dataload)\n",
    "            batch_s1=next(s1_iter)        # S batch\n",
    "                       \n",
    "            if step%n_batch_t == 0:\n",
    "                t_iter = iter(t1_dataload)  # target\n",
    "            batch_t=next(t_iter)\n",
    "            \n",
    "            S1_f = batch_s1[0][0].float()\n",
    "            S1_f = S1_f.to(device)\n",
    "            S1_l = batch_s1[0][1].type(torch.LongTensor)\n",
    "            S1_l = S1_l.to(device)\n",
    "            #print(S1_l)\n",
    "            \n",
    "            t_f = batch_t[0][0].float()\n",
    "            t_f = t_f.to(device)\n",
    "\n",
    "            t_f_out = base_model(t_f)\n",
    "\n",
    "            S1_f_out = base_model(S1_f) \n",
    "\n",
    "            t_f_out = base_model(t_f)\n",
    "            \n",
    "            # classifier output\n",
    "            \n",
    "            S1_out = classifier(S1_f_out)\n",
    "            \n",
    "            # Discriminator output\n",
    "            \n",
    "            S1_out_dis = discriminator(S1_f_out, alpha = alpha)\n",
    "            t_out_dis = discriminator(t_f_out, alpha = alpha)\n",
    "            \n",
    "            s1_dis_l = torch.zeros(S1_out_dis.shape[0]).type(torch.LongTensor).to(device)\n",
    "            t_dis_l = torch.ones(t_out_dis.shape[0]).type(torch.LongTensor).to(device)\n",
    "            \n",
    "            ## loss calculations\n",
    "            \n",
    "            \n",
    "            cl_loss1 = loss_class(S1_out, S1_l)\n",
    "            \n",
    "            cl_loss_avg +=cl_loss1.item()\n",
    "            \n",
    "            d1_loss = criterion(S1_out_dis, s1_dis_l)\n",
    "            d2_loss = criterion(t_out_dis, t_dis_l)\n",
    "            \n",
    "            d_loss = (d1_loss + d2_loss)/2\n",
    "            #print(d_loss)\n",
    "            d_loss_avg +=d_loss.item()\n",
    "            \n",
    "            #total_loss = cl_loss1 + d_loss\n",
    "            \n",
    "            total_loss = [cl_loss1, d_loss]\n",
    "            \n",
    "            \n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            \n",
    "            optimizer.pc_backward(total_loss)\n",
    "            \n",
    "            #total_loss.backward() # backprop\n",
    "            optimizer.step()\n",
    "            \n",
    "            step=step+1\n",
    "        cl_loss_avg /= iteration\n",
    "        d_loss_avg /= iteration\n",
    "        dd=test(t_file_list, base_model, classifier)\n",
    "        print(dd*100)\n",
    "        cl_loss_list.append(cl_loss_avg.item())\n",
    "        d_loss_list.append(d_loss_avg.item())\n",
    "    my_plot(np.linspace(1, num_epoch, num_epoch).astype(int), cl_loss_list)\n",
    "    my_plot(np.linspace(1, num_epoch, num_epoch).astype(int), d_loss_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e936297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model input parameters\n",
    "inputdim = 2048\n",
    "hidden1_out = 1024\n",
    "output_dim = 512\n",
    "\n",
    "numclasses = 14\n",
    "\n",
    "root = \"/home/sayan/Desktop/code_2023/RS_data\"\n",
    "#root =\"/home/sayan/Desktop/code_2023/RS_data/EarthonCanvas\"\n",
    "dataset = \"EarthonCanvas\"\n",
    "source =  \"Aerialsketch\"\n",
    "target = \"AerialPhoto\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57dd83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "epoch___________________ 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/350 [00:00<?, ?it/s]/home/sayan/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n",
      "/home/sayan/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "100%|████████████████████████████████████████| 350/350 [01:01<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.313795568263046\n",
      "epoch___________________ 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 350/350 [01:00<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.81701215153681\n",
      "epoch___________________ 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 350/350 [01:00<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.748391708363116\n",
      "epoch___________________ 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 350/350 [01:00<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.6783416726233\n",
      "epoch___________________ 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 350/350 [01:00<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.31879914224446\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = Feature_Extractor()\n",
    "classifier = ClassClassifier(inputdim, numclasses)\n",
    "discriminator = DomainClassifier(inputdim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0001\n",
    "\n",
    "params = list(base_model.parameters()) + list(classifier.parameters()) + list(discriminator.parameters())\n",
    "#optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "optimizer = PCGrad(optim.Adam(params, lr=learning_rate))\n",
    "\n",
    "shuffle1=True\n",
    "drop_last = True\n",
    "batch_size = 4\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epoch= 5\n",
    "save_path=\"./save_model\"\n",
    "\n",
    "###################################\n",
    "\n",
    "training(root, dataset, base_model, classifier, discriminator, criterion, optimizer,source, target, \n",
    "             device, num_epoch, save_path, batch_size, shuffle1, drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed55330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31cf1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
